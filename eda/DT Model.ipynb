{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 636 candidates, totalling 3180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 312 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done 3180 out of 3180 | elapsed:    7.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Criterion: entropy\n",
      "Best max_depth: 4\n",
      "Best Number Of Components: 33\n",
      "\n",
      "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',\n",
      "                       max_depth=4, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best')\n",
      "Fitting 5 folds for each of 684 candidates, totalling 3420 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 312 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done 3420 out of 3420 | elapsed:    6.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Criterion: gini\n",
      "Best max_depth: 4\n",
      "Best Number Of Components: 2\n",
      "\n",
      "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=4, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best')\n",
      "Fitting 5 folds for each of 744 candidates, totalling 3720 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 312 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done 3720 out of 3720 | elapsed:    6.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Criterion: gini\n",
      "Best max_depth: 2\n",
      "Best Number Of Components: 2\n",
      "\n",
      "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=2, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best')\n",
      "Fitting 5 folds for each of 612 candidates, totalling 3060 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 312 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done 3060 out of 3060 | elapsed:    6.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Criterion: entropy\n",
      "Best max_depth: 8\n",
      "Best Number Of Components: 24\n",
      "\n",
      "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',\n",
      "                       max_depth=8, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best')\n",
      "Fitting 5 folds for each of 648 candidates, totalling 3240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 312 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done 3240 out of 3240 | elapsed:    6.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Criterion: gini\n",
      "Best max_depth: 2\n",
      "Best Number Of Components: 26\n",
      "\n",
      "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=2, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best')\n",
      "Fitting 5 folds for each of 672 candidates, totalling 3360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 312 tasks      | elapsed:    0.8s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import decomposition\n",
    "from sklearn import tree\n",
    "from sklearn.pipeline import Pipeline\n",
    "from warnings import simplefilter\n",
    "import matplotlib.ticker as mtick\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "simplefilter(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "\n",
    "results = []\n",
    "periods = [(10,10),(10,15),(10,20),(15,10),(15,15),(15,20),(20,20),(20,40),(30,60)]\n",
    "\n",
    "\n",
    "for period in periods:\n",
    "    \n",
    "    j = period[0]\n",
    "    k = period[1]\n",
    "\n",
    "    features = pd.read_csv('daily_j' + str(j) + '_k' + str(k)+'_features.csv')\n",
    "    pct = pd.read_csv('daily_j' + str(j) + '_k' + str(k)+'_pct.csv')\n",
    "\n",
    "    corr = features.corr() \n",
    "    #fig, ax = plt.subplots(figsize = (18, 18)) \n",
    "    #sns.heatmap(corr[['label']], square=True) \n",
    "\n",
    "    correlated_features = set()\n",
    "    for i in range(len(corr.columns)):\n",
    "        for a in range(i):\n",
    "            if abs(corr.iloc[i, a]) > 0.90:\n",
    "                colname = corr.columns[i]\n",
    "                correlated_features.add(colname)\n",
    "\n",
    "    num_colums = ['uint8','int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    numerical_columns = list(features.select_dtypes(include=num_colums).columns)\n",
    "    df = features[numerical_columns]\n",
    "    df\n",
    "\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    pca = decomposition.PCA()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df.drop('label',axis=1), \n",
    "                                                        df['label'], train_size=0.538, shuffle=False)\n",
    "    X_before = X_test\n",
    "    X_test = X_test.dropna()\n",
    "    X_train = X_train.dropna()\n",
    "\n",
    "    X_train.drop(columns=correlated_features, axis=1, inplace=True)\n",
    "    X_test.drop(columns=correlated_features, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "    scaler.fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    #y_train.hist()\n",
    "\n",
    "    dec_tree = tree.DecisionTreeClassifier()\n",
    "    pipe = Pipeline(steps=[('std_slc', scaler),\n",
    "                               ('pca', pca),\n",
    "                               ('dec_tree', dec_tree)])\n",
    "    n_components = list(range(1,X_train.shape[1]+1,1))\n",
    "\n",
    "    criterion = ['gini', 'entropy']\n",
    "    max_depth = [2,4,6,8,10,12]\n",
    "\n",
    "    parameters = dict(pca__n_components=n_components,\n",
    "                          dec_tree__criterion=criterion,\n",
    "                          dec_tree__max_depth=max_depth)\n",
    "\n",
    "    clf_GS = GridSearchCV(pipe, parameters,n_jobs=-1,verbose=True)\n",
    "    clf_GS.fit(X_train, y_train)\n",
    "\n",
    "    print('Best Criterion:', clf_GS.best_estimator_.get_params()['dec_tree__criterion'])\n",
    "    print('Best max_depth:', clf_GS.best_estimator_.get_params()['dec_tree__max_depth'])\n",
    "    print('Best Number Of Components:', clf_GS.best_estimator_.get_params()['pca__n_components'])\n",
    "    print(); print(clf_GS.best_estimator_.get_params()['dec_tree'])\n",
    "\n",
    "\n",
    "    predictions = clf_GS.predict(X_test)\n",
    "    predictions\n",
    "\n",
    "    # scores = cross_val_score(clf_GS, X_train, y_train, cv=10)\n",
    "    #print('Cross-Validation Accuracy Scores', scores)\n",
    "\n",
    "\n",
    "    X_before['label'] = predictions.tolist()\n",
    "    X_before\n",
    "\n",
    "    performance =pct[['date','index', 'mom_pct_change','rev_pct_change','SP500_pct_change']].infer_objects()\n",
    "    performance['date'] = pd.to_datetime(performance['date'])\n",
    "    performance = performance.set_index('date')\n",
    "    performance = performance.merge(X_before[['label']], left_on='index', right_index=True) #example\n",
    "    performance['test_pct_change'] = performance.apply(lambda x: x['mom_pct_change'] if x['label']==1 else x['rev_pct_change'] if x['label']==-1 else 0,axis=1) # todo build more models and get their outputs. output results here\n",
    "\n",
    "    performance[['mom_return','rev_return', 'test_return']] = performance[['mom_pct_change','rev_pct_change', 'test_pct_change']].apply(lambda x: (x+1).cumprod()-1)*100\n",
    "    \n",
    "    results.append([j,k,f1_score(y_test,predictions,average='weighted'),predictions,performance['test_return'][-1]])\n",
    "    \n",
    "    # import matplotlib.ticker as mtick\n",
    "\n",
    "    plt = performance[['mom_return','rev_return', 'test_return']].plot(figsize=(15,10),title='J={0} Days, K={1} Days Cummulative Return'.format(j,k),xlabel=\"Date\",ylabel=\"Percent Return\",fontsize=12,color=['green','red','blue'])\n",
    "    plt.legend(['Momentum','Reversal','Strategy'])\n",
    "    fmt = '%.0f%%' # Format you want the ticks, e.g. '40%'\n",
    "    yticks = mtick.FormatStrFormatter(fmt)\n",
    "    plt.yaxis.set_major_formatter(yticks)\n",
    "    plt.get_figure().savefig('dt_performance_j{0}_k{1}.png'.format(j,k))\n",
    "\n",
    "df = pd.DataFrame(results,columns=['j','k','f_score','predictions','test_return']).to_csv('dt_results.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
