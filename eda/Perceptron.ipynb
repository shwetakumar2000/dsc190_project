{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "j = 15\n",
    "k = 10\n",
    "\n",
    "features = pd.read_csv('daily_j' + str(j) + '_k' + str(k)+'_features.csv')\n",
    "pct = pd.read_csv('daily_j' + str(j) + '_k' + str(k)+'_pct.csv')\n",
    "\n",
    "corr = features.corr() \n",
    "fig, ax = plt.subplots(figsize = (18, 18)) \n",
    "sns.heatmap(corr[['label']], square=True) \n",
    "\n",
    "correlated_features = set()\n",
    "for i in range(len(corr.columns)):\n",
    "    for a in range(i):\n",
    "        if abs(corr.iloc[i, a]) > 0.90:\n",
    "            colname = corr.columns[i]\n",
    "            correlated_features.add(colname)\n",
    "\n",
    "num_colums = ['uint8','int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "numerical_columns = list(features.select_dtypes(include=num_colums).columns)\n",
    "df = features[numerical_columns]\n",
    "df\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop('label',axis=1), \n",
    "                                                    df['label'], train_size=0.538,shuffle=False)\n",
    "X_before = X_test\n",
    "X_train = X_train.dropna()\n",
    "X_test = X_test.dropna()\n",
    "\n",
    "X_train.drop(columns=correlated_features, axis=1, inplace=True)\n",
    "X_test.drop(columns=correlated_features, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "y_train.hist()\n",
    "\n",
    "mlp = MLPClassifier(max_iter=500)\n",
    "parameter_space = {\n",
    "    'hidden_layer_sizes': [(50,50,50), (50,100,50), (100,)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'alpha': [0.0001, 0.05],\n",
    "    'learning_rate': ['constant','adaptive'],\n",
    "}\n",
    "\n",
    "\n",
    "clf = GridSearchCV(mlp, parameter_space, n_jobs=-1, cv=3,verbose=True)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "clf.best_params_\n",
    "\n",
    "predictions = clf.predict(X_test)\n",
    "predictions\n",
    "\n",
    "print(classification_report(y_test,predictions))\n",
    "\n",
    "X_before['label'] = predictions.tolist()\n",
    "\n",
    "performance =pct[['date','index', 'mom_pct_change','rev_pct_change','SP500_pct_change']].infer_objects()\n",
    "performance['date'] = pd.to_datetime(performance['date'])\n",
    "# output = date.merge(performance, how='right',left_index=True, right_index=True)[['date','index', 'mom_pct_change','rev_pct_change','SP500_pct_change']]\n",
    "# output\n",
    "# output.to_csv(csv_)\n",
    "performance = performance.set_index('date')\n",
    "performance = performance.merge(X_before[['label']], left_on='index', right_index=True) #example\n",
    "performance['test_pct_change'] = performance.apply(lambda x: x['mom_pct_change'] if x['label']==1 else x['rev_pct_change'] if x['label']==-1 else 0,axis=1) # todo build more models and get their outputs. output results here\n",
    "\n",
    "performance[['mom_return','rev_return', 'test_return']] = performance[['mom_pct_change','rev_pct_change', 'test_pct_change']].apply(lambda x: (x+1).cumprod()-1)*100\n",
    "#performance[['mom_return','rev_return', 'test_return']] = performance[['mom_pct_change','rev_pct_change', 'test_pct_change']].apply(lambda x: np.log(1 + x).cumsum())\n",
    "performance\n",
    "performance[['mom_return_diff','rev_return_diff', 'test_return_diff']] = performance[['mom_pct_change','rev_pct_change', 'test_pct_change']].diff()\n",
    "performance['mom_sharpe_ratio'] = performance['mom_return'].mean()/performance['mom_return'].std() * np.sqrt(252)\n",
    "\n",
    "import matplotlib.ticker as mtick\n",
    "\n",
    "plt = performance[['mom_return','rev_return', 'test_return']].plot(figsize=(15,10),title='J={0} Days, K={1} Days Cummulative Return'.format(j,k),xlabel=\"Date\",ylabel=\"Percent Return\",fontsize=12,color=['green','red','blue'])\n",
    "plt.legend(['Momentum','Reversal','Strategy'])\n",
    "fmt = '%.0f%%' # Format you want the ticks, e.g. '40%'\n",
    "yticks = mtick.FormatStrFormatter(fmt)\n",
    "plt.yaxis.set_major_formatter(yticks)\n",
    "plt.get_figure().savefig('mlp_performance_j{0}_k{1}.png'.format(j,k))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
